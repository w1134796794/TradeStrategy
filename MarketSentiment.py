import akshare as ak
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, Optional
import logging
from dataclasses import dataclass
import time
from TradeDate import TradeCalendar
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class MarketSentimentConfig:
    """å¸‚åœºæƒ…ç»ªåˆ†æé…ç½®å‚æ•°"""
    # æŒ‡æ•°æƒé‡é…ç½®ï¼ˆæ€»å’Œå»ºè®®ä¸º1ï¼‰
    index_weights = {
        "sh000001": 0.4,  # ä¸Šè¯æŒ‡æ•°
        "sz399001": 0.3,  # æ·±è¯æˆæŒ‡
        "sz399006": 0.3  # åˆ›ä¸šæ¿æŒ‡
    }

    # è¯„åˆ†æ¨¡å‹å‚æ•°
    base_score: float = 50.0  # åŸºç¡€æƒ…ç»ªåˆ†
    index_weight: float = 0.4  # æŒ‡æ•°ç»´åº¦æƒé‡
    breadth_weight: float = 0.3  # å¸‚åœºå¹¿åº¦æƒé‡
    limit_weight: float = 0.3  # è¿æ¿é«˜åº¦æƒé‡

    # é‡è¯•å‚æ•°
    max_retries: int = 3  # æ¥å£è°ƒç”¨é‡è¯•æ¬¡æ•°
    retry_delay: float = 1.0  # é‡è¯•é—´éš”(ç§’)

    # é‡èƒ½æƒé‡
    volume_weight: float = 0.2


class MarketSentimentAnalyzer:
    """å¸‚åœºæƒ…ç»ªåˆ†æå™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    def __init__(self, config: MarketSentimentConfig = None):
        self.config = config or MarketSentimentConfig()
        self.trade_date = datetime.now().strftime("%Y%m%d")
        self.calendar = TradeCalendar()

        # åˆå§‹åŒ–æ•°æ®ç¼“å­˜
        self._index_data: Optional[Dict] = None
        self._market_breadth: Optional[Dict] = None
        self._limit_stats: Optional[Dict] = None
        self._listing_dates = {}
        self.new_stock_threshold: int = 5  # ä¸Šå¸‚å¤©æ•°é˜ˆå€¼ï¼ˆäº¤æ˜“æ—¥ï¼‰

        self.market_amplitude = {
            'main_board': 0.18,  # ä¸»æ¿60/00å¼€å¤´
            'gem': 0.36,  # åˆ›ä¸šæ¿30å¼€å¤´
            'star': 0.36,  # ç§‘åˆ›æ¿68å¼€å¤´
            'bj': 0.45  # åŒ—äº¤æ‰€43/83/87å¼€å¤´
        }

        # æƒ…ç»ªè¯„åˆ†å‚æ•°
        self.extreme_score_config = {
            'sky_earth_penalty': -3,  # å¤©åœ°æ¿æ‰£åˆ†
            'earth_sky_bonus': 2,  # åœ°å¤©æ¿åŠ åˆ†
            'st_penalty_factor': 1.5  # STè‚¡å½±å“ç³»æ•°
        }

        self._index_name_map = {
            "sh000001": "ä¸Šè¯æŒ‡æ•°",
            "sz399001": "æ·±è¯æˆæŒ‡",
            "sz399006": "åˆ›ä¸šæ¿æŒ‡",
            "sz399005": "ä¸­å°æ¿æŒ‡",
            "sh000016": "ä¸Šè¯50",
            "sh000905": "ä¸­è¯500",
            "sh000300": "æ²ªæ·±300"
        }

    def _get_index_name(self, code: str) -> str:
        """è·å–æŒ‡æ•°ä¸­æ–‡åç§°"""
        return self._index_name_map.get(code, "æœªçŸ¥æŒ‡æ•°")

    def detect_extreme_boards(self) -> Dict:
        """åŸºäºå®æ—¶æŒ¯å¹…çš„æç«¯æ³¢åŠ¨æ£€æµ‹"""
        try:
            # è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…
            spot_df = ak.stock_zh_a_spot_em()
        except Exception as e:
            logger.error(f"å®æ—¶è¡Œæƒ…è·å–å¤±è´¥: {str(e)}")
            return {'sky_earth': 0, 'earth_sky': 0}

        extreme_cases = {'sky_earth': 0, 'earth_sky': 0, 'details': []}

        for _, row in spot_df.iterrows():
            try:
                # åŸºç¡€æ•°æ®æ ¡éªŒ
                if self._is_new_stock(row['ä»£ç ']):
                    continue

                if pd.isna(row['æŒ¯å¹…']) or pd.isna(row['æœ€æ–°ä»·']):
                    continue

                # è·å–å¸‚åœºç±»å‹
                market = self._get_market_type(row['ä»£ç '])
                if market not in self.market_amplitude:
                    continue

                # è·å–å…³é”®æ•°æ®
                amplitude = row['æŒ¯å¹…'] / 100  # è½¬æ¢ç™¾åˆ†æ¯”ä¸ºå°æ•°
                last_price = row['æœ€æ–°ä»·']
                prev_close = row['æ˜¨æ”¶']
                is_st = 'ST' in row['åç§°']

                # è®¡ç®—æ¶¨è·Œæ–¹å‘
                price_change = (last_price - prev_close) / prev_close

                # åˆ¤æ–­é€»è¾‘
                if amplitude >= self.market_amplitude[market]:
                    # åœ°å¤©æ¿æ¡ä»¶ï¼šæŒ¯å¹…è¾¾æ ‡ä¸”æœ€æ–°ä»·é«˜äºæ˜¨æ—¥æ”¶ç›˜
                    if price_change > 0:
                        extreme_cases['earth_sky'] += 1
                        extreme_cases['details'].append({
                            'code': row['ä»£ç '],
                            'name': row['åç§°'],
                            'type': 'åœ°å¤©æ¿',
                            'amplitude': amplitude,
                            'change_pct': price_change * 100
                        })
                    # å¤©åœ°æ¿æ¡ä»¶ï¼šæŒ¯å¹…è¾¾æ ‡ä¸”æœ€æ–°ä»·ä½äºæ˜¨æ—¥æ”¶ç›˜
                    else:
                        extreme_cases['sky_earth'] += 1
                        extreme_cases['details'].append({
                            'code': row['ä»£ç '],
                            'name': row['åç§°'],
                            'type': 'å¤©åœ°æ¿',
                            'amplitude': amplitude,
                            'change_pct': price_change * 100
                        })
            except Exception as e:
                logger.warning(f"å¤„ç†{row['ä»£ç ']}æ—¶å¼‚å¸¸: {str(e)}")

        return extreme_cases

    def _get_listing_date(self, symbol: str) -> Optional[datetime]:
        """è·å–ä¸Šå¸‚æ—¥æœŸï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if symbol not in self._listing_dates:
            try:
                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                df = ak.stock_individual_info_em(symbol=symbol)

                # æå–ä¸Šå¸‚æ—¥æœŸå­—æ®µ
                date_row = df[df['item'] == 'ä¸Šå¸‚æ—¶é—´']
                if date_row.empty:
                    logger.warning(f"è‚¡ç¥¨{symbol}æ— ä¸Šå¸‚æ—¥æœŸä¿¡æ¯")
                    return None

                # å¤„ç†ä¸åŒæ•°æ®æ ¼å¼
                raw_date = date_row['value'].iloc[0]

                # ç±»å‹è½¬æ¢å’Œæ ¼å¼å¤„ç†
                if isinstance(raw_date, int):  # å¤„ç†æ•°å­—æ ¼å¼æ—¥æœŸ
                    date_str = str(raw_date)
                    if len(date_str) == 8:  # æ ¼å¼å¦‚20230830
                        return datetime.strptime(date_str, "%Y%m%d")
                    else:  # å¤„ç†å…¶ä»–æ•°å­—æ ¼å¼
                        logger.warning(f"è‚¡ç¥¨{symbol}å¼‚å¸¸æ—¥æœŸæ ¼å¼: {raw_date}")
                        return None
                elif isinstance(raw_date, str):  # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼è§£æ
                    for fmt in ("%Y-%m-%d", "%Y/%m/%d", "%Y%m%d"):
                        try:
                            return datetime.strptime(raw_date, fmt)
                        except ValueError:
                            continue
                    logger.warning(f"è‚¡ç¥¨{symbol}æ— æ³•è§£æçš„æ—¥æœŸæ ¼å¼: {raw_date}")
                    return None
                else:  # æœªçŸ¥ç±»å‹
                    logger.warning(f"è‚¡ç¥¨{symbol}æ—¥æœŸå­—æ®µç±»å‹å¼‚å¸¸: {type(raw_date)}")
                    return None

            except Exception as e:
                logger.error(f"è·å–{symbol}ä¸Šå¸‚æ—¥æœŸå¤±è´¥: {str(e)}")
                return None
        return self._listing_dates[symbol]

    def _is_new_stock(self, symbol: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ–°è‚¡æ¬¡æ–°è‚¡"""
        listing_date = self._get_listing_date(symbol)
        if not listing_date:
            return False  # è·å–å¤±è´¥æ—¶ä¸æ’é™¤

        # è®¡ç®—å®é™…äº¤æ˜“æ—¥å·®
        trade_days = self.calendar.get_trade_days(
            start_date=listing_date.strftime("%Y%m%d"),
            end_date=self.trade_date
        )
        return len(trade_days) <= self.new_stock_threshold

    def calculate_extreme_score(self, extreme_data: Dict) -> float:
        """è®¡ç®—æç«¯æ³¢åŠ¨å¾—åˆ†"""
        score = 0
        # åŸºç¡€å¾—åˆ†è®¡ç®—
        score += extreme_data['sky_earth'] * self.extreme_score_config['sky_earth_penalty']
        score += extreme_data['earth_sky'] * self.extreme_score_config['earth_sky_bonus']

        # STè‚¡é¢å¤–æƒ©ç½š
        st_count = sum(1 for d in extreme_data['details'] if 'ST' in d['name'])
        score *= self.extreme_score_config['st_penalty_factor'] ** st_count

        return score

    def _get_market_type(self, code: str) -> str:
        """å¸‚åœºç±»å‹è¯†åˆ«"""
        prefix_map = {
            '60': 'main_board',
            '00': 'main_board',
            '30': 'gem',
            '68': 'star',
            '43': 'bj',
            '83': 'bj',
            '87': 'bj'
        }
        return prefix_map.get(code[:2], 'unknown')

    def _safe_api_call(self, api_func, *args, **kwargs):
        """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
        for attempt in range(1, self.config.max_retries + 1):
            try:
                return api_func(*args, **kwargs)
            except Exception as e:
                logger.warning(f"æ¥å£è°ƒç”¨ç¬¬{attempt}æ¬¡å¤±è´¥: {str(e)}")
                if attempt == self.config.max_retries:
                    raise
                time.sleep(self.config.retry_delay)

    def fetch_index_data(self) -> Dict:
        """è·å–å¹¶å¤„ç†æŒ‡æ•°æ•°æ®"""
        index_data = {}

        for index_code, weight in self.config.index_weights.items():
            try:
                df = self._safe_api_call(ak.stock_zh_index_daily, symbol=index_code)
                if df.empty:
                    continue

                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                df = df.iloc[-30:]  # ä¿ç•™æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥
                df['ma5'] = df['close'].rolling(5).mean()
                df['ma20'] = df['close'].rolling(20).mean()
                last = df.iloc[-1]

                index_data[index_code] = {
                    'change_pct': (last['close'] - last['open']) / last['open'] * 100,
                    'position': 'above' if last['close'] > last['ma5'] else 'below',
                    'trend': 'up' if last['ma5'] > last['ma20'] else 'down',
                    'weight': weight
                }

            except Exception as e:
                logger.error(f"æŒ‡æ•°{index_code}æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")

        return index_data

    def fetch_market_breadth(self) -> Dict:
        """è·å–å¸‚åœºå¹¿åº¦æ•°æ®"""
        try:
            df = self._safe_api_call(ak.stock_market_activity_legu)
            breadth_items = {
                'rise_num': ('ä¸Šæ¶¨', int),
                'fall_num': ('ä¸‹è·Œ', int),
                'limit_up': ('çœŸå®æ¶¨åœ', int),
                'limit_down': ('çœŸå®è·Œåœ', int)
            }

            result = {}
            for key, (name, dtype) in breadth_items.items():
                try:
                    value = df[df['item'] == name]['value'].iloc[0]
                    result[key] = dtype(value)
                except (IndexError, KeyError, ValueError) as e:
                    logger.warning(f"å¸‚åœºå¹¿åº¦å­—æ®µ[{name}]è·å–å¤±è´¥: {str(e)}")
                    result[key] = 0
            return result
        except Exception as e:
            logger.error(f"å¸‚åœºå¹¿åº¦æ•°æ®è·å–å¤±è´¥: {str(e)}")
            return {k: 0 for k in breadth_items.keys()}

    def fetch_limit_stats(self) -> Dict:
        """ç²¾ç¡®è§£ææ¶¨åœç»Ÿè®¡æ•°æ®"""
        try:
            zt_data = ak.stock_zt_pool_em(date=self.trade_date)
            if zt_data.empty:
                return {'max_limit': 0, 'distribution': {}, 'non_consecutive': []}

            # è°ƒè¯•æ‰“å°å‰3è¡Œæ•°æ®
            logger.debug("æ¶¨åœæ± åŸå§‹æ•°æ®æ ·ä¾‹:\n%s", zt_data.head(3).to_string())

            non_consecutive = []
            for _, row in zt_data.iterrows():
                try:
                    # è§£ææ¶¨åœç»Ÿè®¡å­—æ®µ
                    if '/' not in str(row['æ¶¨åœç»Ÿè®¡']):
                        logger.warning(f"è‚¡ç¥¨{row['ä»£ç ']}å¼‚å¸¸æ¶¨åœç»Ÿè®¡æ ¼å¼: {row['æ¶¨åœç»Ÿè®¡']}")
                        continue

                    total_days, limit_times = map(int, str(row['æ¶¨åœç»Ÿè®¡']).split('/'))
                    consecutive_days = row['è¿æ¿æ•°']

                    # è®¡ç®—éè¿ç»­æ¶¨åœæ¬¡æ•°
                    if limit_times > consecutive_days:
                        non_consecutive.append({
                            'code': row['ä»£ç '],
                            'name': row['åç§°'],
                            'total_days': total_days,  # æ€»äº¤æ˜“å¤©æ•°
                            'limit_times': limit_times,  # æ€»æ¶¨åœæ¬¡æ•°
                            'consecutive_days': consecutive_days,  # æœ€å¤§è¿æ¿
                            'non_consecutive': limit_times - consecutive_days  # éè¿ç»­æ¬¡æ•°
                        })
                except Exception as e:
                    logger.warning(f"å¤„ç†{row['ä»£ç ']}æ—¶å¼‚å¸¸: {str(e)}")

            return {
                'max_limit': zt_data['è¿æ¿æ•°'].max(),
                'distribution': zt_data['è¿æ¿æ•°'].value_counts().to_dict(),
                'non_consecutive': non_consecutive
            }
        except Exception as e:
            logger.error(f"æ¶¨åœæ•°æ®è·å–å¤±è´¥: {str(e)}")
            return {'max_limit': 0, 'distribution': {}, 'non_consecutive': []}

    def _format_limit_stats(self) -> Dict:
        """å¢å¼ºç‰ˆæ ¼å¼åŒ–è¾“å‡º"""
        stats = {
            'æœ€é«˜è¿æ¿æ•°': self._limit_stats['max_limit'],
            'è¿æ¿åˆ†å¸ƒ': {f"{k}è¿æ¿": v for k, v in self._limit_stats['distribution'].items()},
            'ç‰¹æ®Šæ¶¨åœæ¡ˆä¾‹': []
        }

        for case in self._limit_stats['non_consecutive']:
            stats['ç‰¹æ®Šæ¶¨åœæ¡ˆä¾‹'].append(
                f"{case['name']}({case['code']}): "
                f"{case['total_days']}ä¸ªäº¤æ˜“æ—¥å†…{case['limit_times']}æ¬¡æ¶¨åœï¼Œ"
                f"æœ€é•¿{case['consecutive_days']}è¿æ¿ï¼Œ"
                f"éè¿ç»­æ¶¨åœ{case['non_consecutive']}æ¬¡"
            )

        return stats

    def collect_market_data(self) -> Dict:
        """æ•´åˆå¸‚åœºæ•°æ®"""
        self._index_data = self.fetch_index_data()
        self._market_breadth = self.fetch_market_breadth()
        self._limit_stats = self.fetch_limit_stats()

        if self.trade_date:
            prev_date = self.calendar.get_previous_trade_date(self.trade_date)

        return {
            'index_data': self._index_data,
            'market_breadth': self._market_breadth,
            'limit_stats': self._limit_stats,
            'trade_date': self.trade_date
        }

    def calculate_index_score(self) -> float:
        """è®¡ç®—æŒ‡æ•°ç»´åº¦å¾—åˆ†"""
        total_score = 0.0

        for code, data in self._index_data.items():
            weight = data.get('weight', 0)

            # è¶‹åŠ¿è¯„åˆ†ï¼ˆ0-20åˆ†ï¼‰
            trend_score = 20 if data['trend'] == 'up' else 0

            # ä½ç½®è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
            position_score = 10 if data['position'] == 'above' else 0

            # æ¶¨è·Œå¹…è¯„åˆ†ï¼ˆ-20~20åˆ†ï¼‰
            change_score = max(min(data['change_pct'] * 2, 20), -20)

            # åŠ æƒè®¡ç®—
            total_score += (trend_score + position_score + change_score) * weight

        return total_score * self.config.index_weight

    def calculate_breadth_score(self) -> float:
        """è®¡ç®—å¸‚åœºå¹¿åº¦å¾—åˆ†"""
        breadth = self._market_breadth

        # ä¸Šæ¶¨æ¯”ä¾‹å¾—åˆ†ï¼ˆ0-30åˆ†ï¼‰
        rise_ratio = breadth['rise_num'] / max(breadth['rise_num'] + breadth['fall_num'], 1)
        rise_score = min(rise_ratio * 100, 30)

        # æ¶¨è·Œåœæ¯”å¾—åˆ†ï¼ˆ0-20åˆ†ï¼‰
        limit_ratio = breadth['limit_up'] / max(breadth['limit_down'], 1)
        limit_score = min(np.log1p(limit_ratio) * 10, 20)  # ä½¿ç”¨å¯¹æ•°å‹ç¼©é‡çº§

        # æ¶¨åœæ•°é‡å¥–åŠ±åˆ†
        bonus_score = 10 if breadth['limit_up'] > 50 else 0

        return (rise_score + limit_score + bonus_score) * self.config.breadth_weight

    def calculate_limit_score(self) -> float:
        """è®¡ç®—è¿æ¿é«˜åº¦å¾—åˆ†"""
        stats = self._limit_stats

        # æœ€é«˜è¿æ¿å¾—åˆ†ï¼ˆ0-15åˆ†ï¼‰
        max_score = min(stats['max_limit'] * 5, 15)

        # è¿æ¿åˆ†å¸ƒå¾—åˆ†ï¼ˆ0-10åˆ†ï¼‰
        mid_limit = sum(count for limit, count in stats['distribution'].items() if 3 <= limit < 7)
        distribution_score = 10 if mid_limit > 5 else 5 if mid_limit > 3 else 0

        return (max_score + distribution_score) * self.config.limit_weight

    def calculate_total_score(self) -> float:
        """è®¡ç®—ç»¼åˆæƒ…ç»ªå¾—åˆ†"""
        if not all([self._index_data, self._market_breadth, self._limit_stats]):
            self.collect_market_data()

        total = self.config.base_score
        total += self.calculate_index_score()
        total += self.calculate_breadth_score()
        total += self.calculate_limit_score()

        return max(min(total, 100), 0)  # é™åˆ¶åœ¨0-100åŒºé—´

    def generate_report(self) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        score = self.calculate_total_score()

        return {
            'äº¤æ˜“æ—¥æœŸ': self.trade_date,
            'ç»¼åˆæƒ…ç»ªåˆ†': round(score, 1),
            'å¾—åˆ†æ˜ç»†': {
                'æŒ‡æ•°ç»´åº¦å¾—åˆ†': round(self.calculate_index_score(), 1),
                'å¸‚åœºå¹¿åº¦å¾—åˆ†': round(self.calculate_breadth_score(), 1),
                'è¿æ¿é«˜åº¦å¾—åˆ†': round(self.calculate_limit_score(), 1)
            },
            'å¸‚åœºæ•°æ®': {
                'æŒ‡æ•°æ•°æ®': self._format_index_data(),
                'æ¶¨è·Œç»Ÿè®¡': self._format_market_breadth(),
                'æ¶¨åœåˆ†æ': self._format_limit_stats()
            },
            'æƒ…ç»ªçº§åˆ«': self._get_sentiment_label(score),
            'æœ¯è¯­è¯´æ˜': self._get_glossary()
        }

    def _get_glossary(self) -> Dict:
        """æœ¯è¯­è¯´æ˜å­—å…¸"""
        return {
            'è¿æ¿æ•°': "æŒ‡è¿ç»­æ¶¨åœå¤©æ•°ï¼Œä¾‹å¦‚3è¿æ¿è¡¨ç¤ºè¿ç»­3ä¸ªäº¤æ˜“æ—¥æ¶¨åœ",
            'éè¿ç»­æ¶¨åœ': "ä¾‹å¦‚8å¤©5æ¿è¡¨ç¤ºåœ¨8ä¸ªäº¤æ˜“æ—¥å†…æœ‰5æ—¥æ¶¨åœï¼Œä½†æœªå½¢æˆè¿ç»­æ¶¨åœ",
            'æ–°è‚¡è¿‡æ»¤': "å·²æ’é™¤ä¸Šå¸‚æœªæ»¡60ä¸ªäº¤æ˜“æ—¥çš„è‚¡ç¥¨ï¼ˆæ¶¨è·Œå¹…è§„åˆ™ä¸åŒï¼‰",
            'æœ‰æ•ˆæ¶¨åœ': "å‰”é™¤æ–°è‚¡ã€STè‚¡åçš„çœŸå®æ¶¨åœç»Ÿè®¡"
        }

    def _format_index_data(self) -> Dict:
        """æ ¼å¼åŒ–æŒ‡æ•°æ•°æ®ä¸ºä¸­æ–‡"""
        formatted = {}
        for code, data in self._index_data.items():
            formatted[code] = {
                'åç§°': self._get_index_name(code),
                'å½“æ—¥æ¶¨è·Œå¹…': f"{data['change_pct']:.2f}%",
                'å‡çº¿ä½ç½®': "5æ—¥å‡çº¿ä¸Šæ–¹" if data['position'] == 'above' else "5æ—¥å‡çº¿ä¸‹æ–¹",
                'è¶‹åŠ¿æ–¹å‘': "ä¸Šå‡è¶‹åŠ¿" if data['trend'] == 'up' else "ä¸‹é™è¶‹åŠ¿",
                'æƒé‡å æ¯”': f"{data['weight'] * 100:.1f}%"
            }
        return formatted

    def _format_market_breadth(self) -> Dict:
        """æ ¼å¼åŒ–å¸‚åœºå¹¿åº¦æ•°æ®"""
        return {
            'ä¸Šæ¶¨å®¶æ•°': self._market_breadth['rise_num'],
            'ä¸‹è·Œå®¶æ•°': self._market_breadth['fall_num'],
            'æ¶¨åœæ•°é‡': self._market_breadth['limit_up'],
            'è·Œåœæ•°é‡': self._market_breadth['limit_down'],
            'æ¶¨è·Œæ¯”': f"{self._market_breadth['rise_num'] / self._market_breadth['fall_num']:.2f}:1"
            if self._market_breadth['fall_num'] > 0 else "N/A"
        }

    def _get_sentiment_label(self, score: float) -> str:
        """æ ¹æ®è¯„åˆ†è·å–æƒ…ç»ªçº§åˆ«"""
        if score >= 80:
            return "æåº¦ä¹è§‚"
        elif score >= 60:
            return "ä¹è§‚"
        elif score >= 40:
            return "ä¸­æ€§"
        elif score >= 20:
            return "è°¨æ…"
        else:
            return "æ‚²è§‚"

    def analyze_premium_effect(self, days=30):
        """
        åˆ†æé¦–æ¿æ¬¡æ—¥çš„æº¢ä»·æ•ˆåº”
        :return: è¿‘æœŸé¦–æ¿æ¬¡æ—¥å¹³å‡æº¢ä»·ç‡
        """
        try:
            # è·å–å†å²é¦–æ¿æ•°æ®
            start_date = self.calendar.get_previous_trade_date(self.trade_date, days)
            zt_df = ak.stock_zt_pool_em(start_date)

            # ç­›é€‰é¦–æ¿
            first_zt = zt_df[zt_df['è¿æ¿æ•°'] == 1]

            # è·å–æ¬¡æ—¥å¼€ç›˜ä»·
            premiums = []
            for _, row in first_zt.iterrows():
                next_date = self.calendar.get_next_trade_date(row['æ—¥æœŸ'])
                if next_date:
                    day_kline = ak.stock_zh_a_hist(symbol=row['ä»£ç '], period='daily',
                                                   start_date=next_date, end_date=next_date)
                    if not day_kline.empty:
                        open_pct = (day_kline.iloc[0]['å¼€ç›˜'] / row['æ”¶ç›˜ä»·'] - 1) * 100
                        premiums.append(open_pct)

            return sum(premiums) / len(premiums) if premiums else 0

        except Exception as e:
            logger.error(f"æº¢ä»·åˆ†æå¤±è´¥: {str(e)}")
            return 0

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":

    analyzer = MarketSentimentAnalyzer()
    report = analyzer.generate_report()

    print(f"æœ€é«˜è¿æ¿æ•°: {report['å¸‚åœºæ•°æ®']['æ¶¨åœåˆ†æ']['æœ€é«˜è¿æ¿æ•°']}")
    print("è¿æ¿åˆ†å¸ƒ:")
    for k, v in report['å¸‚åœºæ•°æ®']['æ¶¨åœåˆ†æ']['è¿æ¿åˆ†å¸ƒ'].items():
        print(f"  {k}: {v}å®¶")

    if report['å¸‚åœºæ•°æ®']['æ¶¨åœåˆ†æ']['ç‰¹æ®Šæ¶¨åœæ¡ˆä¾‹']:
        print("\nğŸ“Œ éè¿ç»­æ¶¨åœæ¡ˆä¾‹:")
        for case in report['å¸‚åœºæ•°æ®']['æ¶¨åœåˆ†æ']['ç‰¹æ®Šæ¶¨åœæ¡ˆä¾‹']:
            print(f"  - {case}")

    extreme_data = analyzer.detect_extreme_boards()
    print(f"æ£€æµ‹åˆ°å¤©åœ°æ¿ï¼š{extreme_data['sky_earth']}ä¾‹ï¼Œåœ°å¤©æ¿ï¼š{extreme_data['earth_sky']}ä¾‹")
    print(json.dumps(extreme_data['details'], indent=4, ensure_ascii=False))
